\chapter{Linear algebra notes}\label{ch:linear_algebra}

In this section, we state and prove some useful linear algebra facts.

\section{Schur complement and positive definiteness}\label{sec:schur_complement}

Let $X = \begin{bmatrix}
             A & B^\top\\
             B & C
\end{bmatrix}$
be a symmetric matrix where $A$ and $C$ are invertible.
\begin{definition}
    The Schur complements $X_{/A}$ and $X_{/C}$ are defined as follows:
    \begin{equation*}
        X_{/A} = C - B A^{-1} B^\top
        ,\qquad
        X_{/C} = A - B^\top C^{-1} B
    \end{equation*}
\end{definition}
Schur complements give a way to characterize the fact that X is positive definite and positive semidefinite.
\begin{lemma}\label{lemma:schur_complement_psd}
The following three properties are equivalent:
\begin{enumerate}
    \item $X \succ \0$
    \item $A \succ \0$ and $X_{/A} \succ \0$
    \item $C \succ \0$ and $X_{/C} \succ \0$
\end{enumerate}
As well as the three following ones:
\begin{enumerate}
    \item $X \succeq \0$
    \item $A \succ \0$ and $X_{/A} \succeq \0$
    \item $C \succ \0$ and $X_{/C} \succeq \0$
\end{enumerate}
\end{lemma}
\begin{proof}
    $X$ can be factorized as follows
    \begin{equation*}
        X = \begin{bmatrix}
                I & \0\\
                B^\top C^{-1} & I
        \end{bmatrix}^\top
        \begin{bmatrix}
            A - B^\top C^{-1}B & \0\\
            \0 & C
        \end{bmatrix}
        \begin{bmatrix}
            I & \0\\
            B^\top C^{-1} & I
        \end{bmatrix}
    \end{equation*}
    which means that $X = Q^\top D Q$ where $D$ is a block-diagonal matrix.
    Therefore $X \succ \0$ (resp. $\succeq \0$) if and only if $D \succ \0$ (resp. $\succeq \0$),
    which is equivalent to its diagonal blocks to be $\succ \0$ (resp. $\succeq \0$).
    To get the same result with the complement $X_{/A} = C - B A^{-1} B^\top$,
    we use the factorization
    \begin{equation*}
        X = \begin{bmatrix}
                I & \0\\
                BA^{-1} & I
        \end{bmatrix}
        \begin{bmatrix}
            A & \0\\
            \0 & C - BA^{-1}B^\top
        \end{bmatrix}
        \begin{bmatrix}
            I & \0\\
            BA^{-1} & I
        \end{bmatrix}^\top
    \end{equation*}
\end{proof}

Consider the particular partition
$X = \begin{bmatrix}
         \xi & \yy^\top\\
         \yy & B
\end{bmatrix}$
where $B$ is invertible.
Then a direct application of Lemma~\ref{lemma:schur_complement_psd} gives that
\begin{equation*}
    \begin{cases}
        X \succ \0 \iff B \succ \0 \text{ and } \xi > \yy^\top B^{-1} \yy\\
        X \succeq \0 \iff B \succ \0 \text{ and } \xi \geq \yy^\top B^{-1} \yy
    \end{cases}
\end{equation*}

More results regarding Schur complements can be found in~\cite{schur_complement}.
A generalization involving pseudo-inverses of $A$ and $C$ when they are singular is possible.

\section{Sherman–Morrison–Woodbury formula}\label{sec:sherman}

The Sherman-Morrison formula gives a way to calculate the inverse of the sum of an invertible matrix
$M \in \R^{p \times p}$
and a rank-1 update $uv^\top$.
\begin{lemma}
    (Sherman-Morrison) Let $u,\, v \in \R^p$.
    Then,
    \begin{equation*}
        \big( M + uv^\top \big)^{-1} = M^{-1} - \frac{M^{-1}uv^\top M^{-1}}{1 + v^\top M^{-1}u}
    \end{equation*}
\end{lemma}
It can be generalized to a rank-k update $UV$ as follows.
\begin{lemma}
    (Woodbury) Let $U,\, V \in \R^{p \times k}$.
    Then,
    \begin{equation*}
        \big( M + UV^\top \big)^{-1} = M^{-1} - M^{-1}U \left( I + V^\top M^{-1}U \right)^{-1}V^\top M^{-1}
    \end{equation*}
\end{lemma}
Proofs and further details regarding these formulas can be found in~\cite{woodbury}.

\section{Block matrix determinant}\label{sec:block_matrix_det}

\begin{lemma}
    Let M be partitioned as $M = \begin{bmatrix}
                                     P & Q\\
                                     R & S
    \end{bmatrix}$ where $P$ and $S$ are nonsingular.
    Then,
    \begin{equation*}
        \begin{cases}
            \det M = \det(S)\det(P - QS^{-1}R)\\
            \det M = \det(P)\det(R - RP^{-1}Q)
        \end{cases}
    \end{equation*}
\end{lemma}
\begin{proof}
    Note the following block-matrix identity
    \begin{equation*}
        \begin{bmatrix}
            P & Q\\
            R & S
        \end{bmatrix}
        \begin{bmatrix}
            I & \0\\
            -S^{-1}R & I
        \end{bmatrix}
        =
        \begin{bmatrix}
            P - QS^{-1}R & Q\\
            \0 & S
        \end{bmatrix}
    \end{equation*}
    The fact that the determinant of a block-triangular matrix is the product of the determinants
    of the diagonal blocks gives the result.
    A similar factorization holds for the second identity.
\end{proof}
